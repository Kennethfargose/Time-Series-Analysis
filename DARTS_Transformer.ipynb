{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kennethfargose/Time-Series-Analysis/blob/main/DARTS_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c14dSVMPnUYe"
      },
      "outputs": [],
      "source": [
        "!pip install darts\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SonzzSVdnYYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorboardX"
      ],
      "metadata": {
        "id": "on1wKTl6ds2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sktime"
      ],
      "metadata": {
        "id": "a7MYj-vTP3Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pytest\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import darts\n",
        "from darts import TimeSeries\n",
        "from darts.utils.timeseries_generation import gaussian_timeseries, linear_timeseries, sine_timeseries,datetime_attribute_timeseries\n",
        "from darts.models import RNNModel, TCNModel, TransformerModel, NBEATSModel, BlockRNNModel, NHiTSModel\n",
        "from darts.metrics import mape, smape, rmse,mae,ope, r2_score, rmsle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import datetime as dt\n",
        "from functools import reduce\n",
        "\n",
        "import pmdarima as pmd\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import normaltest\n",
        "from tensorboardX import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "from darts.utils.statistics import check_seasonality, plot_acf, plot_residuals_analysis\n",
        "from darts.dataprocessing.transformers.boxcox import BoxCox\n",
        "import numpy as np\n",
        "from sktime.performance_metrics.forecasting import MeanSquaredScaledError\n",
        "from darts import TimeSeries\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "from darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel, Prophet, AutoARIMA\n",
        "from darts.metrics import mape,mse\n",
        "from darts.utils.statistics import check_seasonality, plot_acf\n",
        "\n",
        "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import logging\n"
      ],
      "metadata": {
        "id": "cwt1vtRbOtwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_dataframe_index(df, index_column):\n",
        "    '''This function is to reset the index since the date isn't recorded'''\n",
        "    return df.set_index(index_column)\n",
        "\n",
        "def multi_uni_df(df, state, store_ids):\n",
        "    '''To select one or more store i.e uni or multi varaint'''\n",
        "    cols = []\n",
        "    for store_id in store_ids:\n",
        "        cols.append(df[state + \"_\" + store_id])\n",
        "    return pd.concat(cols, axis=1)\n",
        "\n",
        "def get_timeseries(df, state, store_ids):\n",
        "    '''This function is to store the timeseries type'''\n",
        "    df_states = multi_uni_df(df, state, store_ids)\n",
        "    ts_type = \"\"\n",
        "    if len(store_ids) == 1:\n",
        "        ts_type = state + \"_\" + store_ids[0] + \"_univariate\"\n",
        "    else:\n",
        "        ts_type = state + \"_\" + \"\".join(store_ids) + \"_multivariate\"\n",
        "    return df_states, ts_type\n",
        "\n",
        "def create_timeseries(df, value_cols):\n",
        "    '''This function makes sure that all name of the columns is constant in this case sale to convert the dataframe to a series'''\n",
        "    if len(df.columns) == 1:\n",
        "        df.columns = ['sale']\n",
        "    else:\n",
        "        for i, col in enumerate(df.columns):\n",
        "            df.rename(columns={col: f\"sale\"}, inplace=True)\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "    return TimeSeries.from_dataframe(df, value_cols=value_cols)\n",
        "\n",
        "def split_timeseries(series, split_date):\n",
        "    '''To split the time series'''\n",
        "    train, val = series.split_after(pd.Timestamp(split_date))\n",
        "    return train, val\n",
        "\n",
        "def get_train_on(ts_type):\n",
        "    train_on_map = {\n",
        "        \"CA_1_univariate\": \"CA_store_1_univariate\",\n",
        "        \"CA_3_univariate\": \"CA_store_3_univariate\",\n",
        "        \"CA_2_univariate\": \"CA_store_2_univariate\",\n",
        "        \"CA_4_univariate\": \"CA_store_4_univariate\",\n",
        "        \"CA_12_multivariate\": \"CA_stores_1_2_multivariate\",\n",
        "        \"CA_23_multivariate\": \"CA_stores_2_3_multivariate\",\n",
        "        \"CA_34_multivariate\": \"CA_stores_3_4_multivariate\",\n",
        "        \"CA_14_multivariate\": \"CA_stores_1_4_multivariate\",\n",
        "        \"WI_1_univariate\": \"WI_stores_1_univariate\",\n",
        "        \"WI_23_multivariate\": \"WI_stores_2_3_multivariate\",\n",
        "        \"WI_31_multivariate\": \"WI_stores_1_3_multivariate\",\n",
        "        \"WI_2_univariate\": \"WI_stores_2_univariate\",\n",
        "        \"WI_3_univariate\": \"WI_stores_3_univariate\",\n",
        "        \"TX_1_univariate\": \"TX_stores_1_univariate\",\n",
        "        \"TX_23_multivariate\": \"TX_stores_2_3_multivariate\",\n",
        "        \"TX_13_multivariate\": \"TX_stores_1_3_multivariate\",\n",
        "        \"TX_2_univariate\": \"TX_stores_2_univariate\",\n",
        "        \"TX_3_univariate\": \"TX_stores_3_univariate\",\n",
        "    }\n",
        "    return train_on_map.get(ts_type, None)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S66xta1bnlAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ca = set_dataframe_index(pd.read_csv(r\"/content/drive/MyDrive/CA_all.csv\"), 'date')\n",
        "df_wi = set_dataframe_index(pd.read_csv(r\"/content/drive/MyDrive/WI_all.csv\"), 'date')\n",
        "df_tx = set_dataframe_index(pd.read_csv(r\"/content/drive/MyDrive/TX_all.csv\"), 'date')"
      ],
      "metadata": {
        "id": "mP1ezOJMqPu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_states, ts_type = get_timeseries(df_ca, \"CA\", [\"3\"])\n",
        "print(ts_type)\n",
        "series = create_timeseries(df_states, value_cols=\"sale\")\n",
        "train, val = split_timeseries(series, '20150522')\n",
        "trained_on = get_train_on(ts_type)\n",
        "print(trained_on)"
      ],
      "metadata": {
        "id": "-Bg4gEgjTZqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_timeseries(series,train,val):\n",
        "    '''To scale the series and the train and val data'''\n",
        "    transformer = Scaler()\n",
        "    train_transformed = transformer.fit_transform(train)\n",
        "    val_transformed = transformer.fit_transform(val)\n",
        "    series_transformed = transformer.fit_transform(series)\n",
        "    return series_transformed,train_transformed,val_transformed"
      ],
      "metadata": {
        "id": "fogT5pd8Ts_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series_transformed, train_transformed, val_transformed = scale_timeseries(series,train,val)"
      ],
      "metadata": {
        "id": "B-MADkg_TwHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model_t = TransformerModel(\n",
        "    input_chunk_length=250,\n",
        "    output_chunk_length=70,\n",
        "    batch_size=32,\n",
        "    n_epochs=50,\n",
        "    model_name=\"transformer\",\n",
        "    nr_epochs_val_period=10,\n",
        "    d_model=64,\n",
        "    nhead=4,\n",
        "    num_encoder_layers=2,\n",
        "    num_decoder_layers=2,\n",
        "    dim_feedforward=128,\n",
        "    dropout=0.1,\n",
        "    activation=\"relu\",\n",
        "    random_state=42,\n",
        "    save_checkpoints=True,\n",
        "    force_reset=True,\n",
        ")"
      ],
      "metadata": {
        "id": "SgHk30-5TzLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "BQoohmuAV0Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time=time.time()\n",
        "my_model_t.fit(series=\n",
        "               train_transformed, val_series=val_transformed, verbose=True)\n",
        "end_time=time.time()\n",
        "time_taken=end_time-start_time"
      ],
      "metadata": {
        "id": "63n62qFZT5ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics_table(timeseries_id_type, datapoints, model_dict, trained_on, val_data, metric_funcs, time_taken):\n",
        "    results = []\n",
        "\n",
        "    for name, model in model_dict.items():\n",
        "        pred_series = model.predict(n=len(val_data))\n",
        "\n",
        "\n",
        "        metric_values = [f(pred_series, val_data) for f in metric_funcs]\n",
        "        results.append([name] + metric_values)\n",
        "\n",
        "    metric_names = [\"timeseries_id_type\", \"datapoints\", \"Trained_on\", \"time taken(s)\", \"Model\"] + [f.__name__ for f in metric_funcs]\n",
        "    metric_values = [timeseries_id_type, datapoints, trained_on, time_taken]\n",
        "    metric_values += [result for result in results[0]]\n",
        "\n",
        "    metrics_table = pd.DataFrame([metric_values], columns=metric_names)\n",
        "\n",
        "    return metrics_table"
      ],
      "metadata": {
        "id": "47peK-BtWJKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = { \"Transfomer\":my_model_t} #\n",
        "metric_funcs = [smape,mape,rmse,mae]\n",
        "datapoints=len(series)\n",
        "timeseries_id_type=ts_type\n",
        "trained_on=trained_on\n",
        "\n",
        "metrics_table = get_metrics_table(timeseries_id_type,datapoints,model_dict,trained_on, val, metric_funcs,time_taken)\n",
        "metrics_table"
      ],
      "metadata": {
        "id": "rrER246QWK3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}